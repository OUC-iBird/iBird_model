{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ibird-2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyODsNsez2ECwQ8rYBG8bUBP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7668d2ccc4fd448a92a04008a95393f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_64803e85b88a4e1f85acef76a5ea8e6a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a403a00921ef470ca7be03fe17be4ca1","IPY_MODEL_c9f2907620584a988ab4fba3736ab5af"]}},"64803e85b88a4e1f85acef76a5ea8e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a403a00921ef470ca7be03fe17be4ca1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2a90f1d37f8242ffab2fd0e221c776c0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":122410125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":122410125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c7e63939b6b4eec8d54bb17ffa139ee"}},"c9f2907620584a988ab4fba3736ab5af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4c551c9d0b7f4e7da3e814e4b77ce649","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 117M/117M [00:01&lt;00:00, 106MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1c5c0a3ea464d759b0ffb65bd23ca31"}},"2a90f1d37f8242ffab2fd0e221c776c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c7e63939b6b4eec8d54bb17ffa139ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c551c9d0b7f4e7da3e814e4b77ce649":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c1c5c0a3ea464d759b0ffb65bd23ca31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"6susXe-Y7o0A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607823636365,"user_tz":-480,"elapsed":8600,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"43b7a137-9ec2-4e94-d4e7-3272005ae0f2"},"source":["!pip install overrides\n","!pip install tqdm\n","!pip install efficientnet_pytorch\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (3.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n","Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.7.0+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P5QHRyF979UG"},"source":["!wget https://dwz.cn/ijPVPQhz\n","!unrar x ijPVPQhz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CY8DBzjHACU4","executionInfo":{"status":"ok","timestamp":1607823799045,"user_tz":-480,"elapsed":910,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["# 头文件\n","from overrides import overrides\n","import torch.nn as nn\n","import torch\n","import pandas as pd\n","from torchvision.datasets.folder import accimage_loader, pil_loader\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim import lr_scheduler\n","import os\n","import torchvision\n","from torchvision import transforms\n","from typing import Tuple\n","from torch.nn import Module\n","from torch.optim.optimizer import Optimizer\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from efficientnet_pytorch import EfficientNet"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"JmliupqIARrg","executionInfo":{"status":"ok","timestamp":1607824789738,"user_tz":-480,"elapsed":1054,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["class Trainer:\n","    \"\"\"Trainer class to abstract rudimentary training loop.\"\"\"\n","\n","    def __init__(\n","            self,\n","            model: Module,\n","            criterion: Module,\n","            optimizer: Optimizer,\n","            device: torch.device) -> None:\n","        \"\"\"Set trainer class with model, criterion, optimizer. (Data is passed to train/eval).\"\"\"\n","        super(Trainer, self).__init__()\n","        self.model: Module = model\n","        self.criterion: Module = criterion\n","        self.optimizer: Optimizer = optimizer\n","        self.device: torch.device = device\n","\n","    def train(self, loader: DataLoader) -> Tuple[float, float]:\n","        \"\"\"Train model using batches from loader and return accuracy and loss.\"\"\"\n","        total_loss, total_acc = 0.0, 0.0\n","        self.model.train()\n","        try:\n","            with tqdm(enumerate(loader), total=len(loader), desc='Training') as proc:\n","                for _, (inputs, targets) in proc:\n","                    inputs = inputs.to(self.device)\n","                    targets = targets.to(self.device)\n","                    outputs = self.model(inputs)\n","                    loss = self.criterion(outputs, targets)\n","                    self.optimizer.zero_grad()\n","                    loss.backward()\n","                    self.optimizer.step()\n","                    _, predicted = torch.max(outputs, 1)\n","                    total_loss += loss.item()\n","                    total_acc += (predicted == targets).float().sum().item() / targets.numel()\n","        except Exception as e:\n","            # 异常情况关闭\n","            print(\"Running Error in training, \", e)\n","            proc.close()\n","            return -1, -1\n","        proc.close()\n","        return total_loss / len(loader), 100.0 * total_acc / len(loader)\n","\n","    def test(self, loader: DataLoader) -> Tuple[float, float]:\n","        \"\"\"Evaluate model using batches from loader and return accuracy and loss.\"\"\"\n","        with torch.no_grad():\n","            total_loss, total_acc = 0.0, 0.0\n","            self.model.eval()\n","            try:\n","                with tqdm(enumerate(loader), total=len(loader), desc='Testing ') as proc:\n","                    for _, (inputs, targets) in proc:\n","                        inputs = inputs.to(self.device)\n","                        targets = targets.to(self.device)\n","                        outputs = self.model(inputs)\n","                        loss = self.criterion(outputs, targets)\n","                        _, predicted = torch.max(outputs, 1)\n","                        total_loss += loss.item()\n","                        total_acc += (predicted == targets).float().sum().item() / targets.numel()\n","            except Exception as e:\n","                proc.close()\n","                print(\"Running Error in validating,\", e)\n","                return -1, -1\n","            proc.close()\n","        return total_loss / len(loader), 100.0 * total_acc / len(loader)\n","\n","    def predict(self, loader: DataLoader):\n","        results = []\n","        for inputs, targets in loader:\n","            inputs = inputs.to(self.device)\n","            outputs = self.model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            results.append(predicted)\n","        return results\n","\n","\n","def run_epochs_for_loop(\n","        trainer: Trainer,\n","        epochs: int,\n","        train_loader: DataLoader,\n","        test_loader: DataLoader,\n","        scheduler: ReduceLROnPlateau = None):\n","    # Run train + evaluation loop for specified epochs.\n","    global best \n","    for epoch in range(epochs):\n","        (train_loss, train_acc) = trainer.train(train_loader)\n","        (test_loss, test_acc) = trainer.test(test_loader)\n","        print()\n","        print(\"Epoch %d: TrainLoss %f \\t TrainAcc %f\" % (epoch+1, train_loss, train_acc))\n","        print(\"Epoch %d: TestLoss %f \\t TestAcc %f\" % (epoch+1, test_loss, test_acc))\n","        # 动态更新学习率\n","        if scheduler is not None:\n","            scheduler.step()\n","        # 保存训练的结果\n","        if test_acc > best:\n","            best = test_acc\n","            save_checkpoint(trainer, epoch, test_acc, \"./\")\n","\n","\n","def save_checkpoint(trainer: Trainer, epoch: int, accuracy: float, path: str):\n","    # 保存训练结果\n","    path = os.path.join(path, \"checkpoint.pt\")\n","    checkpoint = {\n","        \"model\": trainer.model.state_dict(),\n","        \"optimizer\": trainer.optimizer.state_dict(),\n","        \"epoch\": epoch,\n","        \"accuracy\": accuracy,\n","    }\n","    torch.save(checkpoint, path)\n","\n","\n","def save_model(model, path):\n","    # 只保存模型的实例变量\n","    if torch.__version__ >= \"1.6.0\":\n","        torch.save(model.state_dict(), path, _use_new_zipfile_serialization=False)\n","    else:\n","        torch.save(model.state_dict(), path)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"AiHLGa3IsuSn","executionInfo":{"status":"ok","timestamp":1607823645552,"user_tz":-480,"elapsed":1750,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["\r\n","\r\n","def conv3x3(in_planes, out_planes, stride=1):\r\n","    # \"3x3 convolution with padding\"\r\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n","                     padding=1, bias=False)\r\n","\r\n","\r\n","class ChannelAttention(nn.Module):\r\n","    def __init__(self, in_planes, ratio=16):\r\n","        super(ChannelAttention, self).__init__()\r\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # 压缩空间\r\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\r\n","\r\n","        self.fc1 = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\r\n","        self.relu1 = nn.ReLU()\r\n","        self.fc2 = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\r\n","\r\n","        self.sigmoid = nn.Sigmoid()\r\n","\r\n","    def forward(self, x):\r\n","        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\r\n","        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\r\n","        out = avg_out + max_out  # [b, C, 1, 1]\r\n","        return self.sigmoid(out)\r\n","\r\n","\r\n","class SpatialAttention(nn.Module):\r\n","    def __init__(self, kernel_size=7):\r\n","        super(SpatialAttention, self).__init__()\r\n","\r\n","        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\r\n","        padding = 3 if kernel_size == 7 else 1\r\n","\r\n","        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\r\n","        self.sigmoid = nn.Sigmoid()\r\n","\r\n","    def forward(self, x):\r\n","        avg_out = torch.mean(x, dim=1, keepdim=True)  # 压缩通道\r\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)   # 压缩通道\r\n","        x = torch.cat([avg_out, max_out], dim=1)  # [b, 1, h, w]\r\n","        x = self.conv1(x)\r\n","        return self.sigmoid(x)\r\n","\r\n","\r\n","class BasicBlock(nn.Module):\r\n","    expansion = 1\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n","        super(BasicBlock, self).__init__()\r\n","        self.conv1 = conv3x3(inplanes, planes, stride)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.conv2 = conv3x3(planes, planes)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","\r\n","        self.ca = ChannelAttention(planes)\r\n","        self.sa = SpatialAttention()\r\n","\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = x\r\n","\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","\r\n","        out = self.ca(out) * out\r\n","        out = self.sa(out) * out\r\n","\r\n","        if self.downsample is not None:\r\n","            residual = self.downsample(x)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","\r\n","        return out\r\n","\r\n","\r\n","class Bottleneck(nn.Module):\r\n","    expansion = 4\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n","        super(Bottleneck, self).__init__()\r\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\r\n","                               padding=1, bias=False)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\r\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","\r\n","        self.ca = ChannelAttention(planes * 4)\r\n","        self.sa = SpatialAttention()\r\n","\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = x\r\n","\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv3(out)\r\n","        out = self.bn3(out)\r\n","\r\n","        out = self.ca(out) * out\r\n","        out = self.sa(out) * out\r\n","\r\n","        if self.downsample is not None:\r\n","            residual = self.downsample(x)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","\r\n","        return out"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"rymNvtvxs7G1","executionInfo":{"status":"ok","timestamp":1607823649172,"user_tz":-480,"elapsed":1587,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["class EfficientNetWithAttention(nn.Module):\r\n","\r\n","    def __init__(self, num_classes: int = 200):\r\n","        super(EfficientNetWithAttention, self).__init__()\r\n","        self.eff_model = EfficientNet.from_pretrained(\"efficientnet-b5\")\r\n","        self._avg_pooling = nn.AdaptiveAvgPool2d(output_size=1)\r\n","        self._dropout = nn.Dropout(p=0.5, inplace=False)\r\n","\r\n","        self._fc = nn.Linear(in_features=self.eff_model._fc.in_features, out_features=num_classes, bias=True)\r\n","        self.ca_head = ChannelAttention(64)\r\n","        self.sa = SpatialAttention()\r\n","        self.ca_tail = ChannelAttention(self.eff_model._fc.in_features)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.eff_model.extract_features(x)\r\n","        x = self.ca_tail(x) * x\r\n","        x = self.sa(x) * x\r\n","\r\n","        x = self._avg_pooling(x)\r\n","        if self.eff_model._global_params.include_top:\r\n","            x = x.flatten(start_dim=1)\r\n","            x = self._dropout(x)\r\n","            x = self._fc(x)\r\n","        return x"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["7668d2ccc4fd448a92a04008a95393f2","64803e85b88a4e1f85acef76a5ea8e6a","a403a00921ef470ca7be03fe17be4ca1","c9f2907620584a988ab4fba3736ab5af","2a90f1d37f8242ffab2fd0e221c776c0","6c7e63939b6b4eec8d54bb17ffa139ee","4c551c9d0b7f4e7da3e814e4b77ce649","c1c5c0a3ea464d759b0ffb65bd23ca31"]},"id":"wizkwi7MANbJ","executionInfo":{"status":"ok","timestamp":1607823654019,"user_tz":-480,"elapsed":3550,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"3f445816-ab18-47e1-9c25-82243bfaf052"},"source":["\n","data_dir = \"./AI研习社_鸟类识别比赛数据集\"\n","selection = [\"train_set\", \"val_set\"]\n","train_labels = os.path.join(data_dir, \"train_pname_to_index.csv\")\n","valid_labels = os.path.join(data_dir, \"val_pname_to_index.csv\")\n","\n","\n","def default_loader(path):\n","    from torchvision import get_image_backend\n","    if get_image_backend() == 'accimage':\n","        return accimage_loader(path)\n","    else:\n","        return pil_loader(path)\n","\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, data_path, data_label_path, data_transform, data_loader=default_loader):\n","        \"\"\"\n","\n","        :param data_path: 要读取的文件的路径\n","        :param data_label_path: 标签数据的路径\n","        :param data_transform: 数据变换模式\n","        :param data_loader: 加载方法\n","        \"\"\"\n","        # 在label文件中注意不要加上标签\n","        df = pd.read_csv(data_label_path, header=None)\n","        self.data_loader = data_loader\n","        self.data_transform = data_transform\n","        self.data_path = data_path\n","        # 获取文件夹下的全部图片名\n","        self.img_names = list(df[0])\n","        self.labels = list(df[1])\n","\n","    def __len__(self):\n","        return len(self.img_names)\n","\n","    def __getitem__(self, item):\n","        img_name = self.img_names[item]\n","        img_path = os.path.join(self.data_path, img_name)\n","        label = self.labels[item]\n","        img = self.data_loader(img_path)\n","        try:\n","            img = self.data_transform(img)\n","            return img, label-1\n","        except:\n","            raise Exception(\"cannot transform image: {}\".format(img_name))\n","\n","\n","if __name__ == '__main__':\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    formats = {\n","        'train_set': [\n","            transforms.Resize(456),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomRotation(5),\n","            transforms.RandomCrop(456),\n","            transforms.ToTensor(),\n","            normalize,\n","        ],\n","        'val_set': [\n","            transforms.Resize(456),\n","            transforms.CenterCrop(456),\n","            transforms.ToTensor(),\n","            normalize,\n","        ],\n","    }\n","    data_label_paths = {\n","        \"train_set\": train_labels,\n","        \"val_set\": valid_labels,\n","    }\n","    data_sets = {}\n","    for one in selection:\n","        data_sets[one] = CustomDataset(os.path.join(data_dir, one),\n","                                       data_label_paths[one],\n","                                       transforms.Compose(formats[one]))\n","    data_loader = {\n","        \"train\":\n","            torch.utils.data.DataLoader(\n","                data_sets[\"train_set\"],\n","                batch_size=64,\n","                shuffle=True,\n","                num_workers=4\n","            ),\n","\n","        \"valid\": torch.utils.data.DataLoader(\n","                data_sets[\"val_set\"],\n","                batch_size=5,\n","                shuffle=False,\n","                num_workers=4\n","            ),\n","    }\n","    # eff_model = EfficientNet.from_pretrained(\"efficientnet-b5\")\n","    # in_features = eff_model._fc.in_features\n","    # eff_model._fc = nn.Linear(in_features, 200)\n","    eff_model = EfficientNetWithAttention()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b5-b6417697.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7668d2ccc4fd448a92a04008a95393f2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=122410125.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Loaded pretrained weights for efficientnet-b5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6O9kNQpDILnO","executionInfo":{"status":"ok","timestamp":1607840421249,"user_tz":-480,"elapsed":6763559,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"6682c1a8-1eba-4695-e53e-c2251e5ef378"},"source":["data_loader = {\r\n","        \"train\":\r\n","            torch.utils.data.DataLoader(\r\n","                data_sets[\"train_set\"],\r\n","                batch_size=64,\r\n","                shuffle=True,\r\n","                num_workers=4\r\n","            ),\r\n","\r\n","        \"valid\": torch.utils.data.DataLoader(\r\n","                data_sets[\"val_set\"],\r\n","                batch_size=5,\r\n","                shuffle=False,\r\n","                num_workers=4\r\n","            ),\r\n","    }\r\n","for param in eff_model.parameters():\r\n","    param.requires_grad = False\r\n","for param in eff_model._fc.parameters():\r\n","    param.requires_grad = True\r\n","for param in eff_model.ca_tail.parameters():\r\n","    param.requires_grad = True\r\n","for param in eff_model.sa.parameters():\r\n","    param.requires_grad = True\r\n","\r\n","best = 80\r\n","\r\n","# Observe that all parameters are being optimized\r\n","params = filter(lambda p: p.requires_grad, eff_model.parameters())\r\n","optimizer = torch.optim.SGD(params, lr=0.003, momentum=0.9)\r\n","\r\n","# Decay LR by a factor of 0.1 every 7 epochs\r\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\r\n","criterion = nn.CrossEntropyLoss()\r\n","eff_model.to(device)\r\n","criterion.to(device)\r\n","trainer = Trainer(eff_model, criterion, optimizer, device)\r\n","run_epochs_for_loop(trainer, 21, data_loader[\"train\"], data_loader[\"valid\"], exp_lr_scheduler)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Training: 100%|██████████| 129/129 [04:26<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 1: TrainLoss 0.472730 \t TrainAcc 88.753531\n","Epoch 1: TestLoss 1.033943 \t TestAcc 81.487759\n"],"name":"stdout"},{"output_type":"stream","text":["Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.34it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 2: TrainLoss 0.460492 \t TrainAcc 88.884715\n","Epoch 2: TestLoss 1.030026 \t TestAcc 81.544256\n"],"name":"stdout"},{"output_type":"stream","text":["Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 3: TrainLoss 0.459360 \t TrainAcc 89.006865\n","Epoch 3: TestLoss 1.029692 \t TestAcc 81.261770\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 4: TrainLoss 0.448127 \t TrainAcc 89.068454\n","Epoch 4: TestLoss 1.027852 \t TestAcc 81.261770\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 5: TrainLoss 0.411442 \t TrainAcc 89.795198\n","Epoch 5: TestLoss 1.027505 \t TestAcc 81.261770\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:26<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 6: TrainLoss 0.446987 \t TrainAcc 89.214829\n","Epoch 6: TestLoss 1.026661 \t TestAcc 81.261770\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:26<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 7: TrainLoss 0.443294 \t TrainAcc 89.192657\n","Epoch 7: TestLoss 1.024197 \t TestAcc 81.318267\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:26<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 8: TrainLoss 0.431422 \t TrainAcc 89.198611\n","Epoch 8: TestLoss 1.023692 \t TestAcc 81.318267\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:26<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 9: TrainLoss 0.463943 \t TrainAcc 89.212776\n","Epoch 9: TestLoss 1.023673 \t TestAcc 81.374765\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 10: TrainLoss 0.432984 \t TrainAcc 88.961495\n","Epoch 10: TestLoss 1.023656 \t TestAcc 81.374765\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:26<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 11: TrainLoss 0.420285 \t TrainAcc 89.357098\n","Epoch 11: TestLoss 1.021475 \t TestAcc 81.544256\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 12: TrainLoss 0.422886 \t TrainAcc 89.297563\n","Epoch 12: TestLoss 1.021597 \t TestAcc 81.318267\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 13: TrainLoss 0.472070 \t TrainAcc 88.840371\n","Epoch 13: TestLoss 1.023455 \t TestAcc 81.261770\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 14: TrainLoss 0.438851 \t TrainAcc 89.564036\n","Epoch 14: TestLoss 1.022499 \t TestAcc 81.318267\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 15: TrainLoss 0.448842 \t TrainAcc 89.264305\n","Epoch 15: TestLoss 1.022564 \t TestAcc 81.318267\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 16: TrainLoss 0.447492 \t TrainAcc 88.705081\n","Epoch 16: TestLoss 1.024391 \t TestAcc 81.431262\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 17: TrainLoss 0.452595 \t TrainAcc 88.846324\n","Epoch 17: TestLoss 1.022520 \t TestAcc 81.431262\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 18: TrainLoss 0.433614 \t TrainAcc 89.660935\n","Epoch 18: TestLoss 1.023043 \t TestAcc 81.318267\n"],"name":"stdout"},{"output_type":"stream","text":["Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 19: TrainLoss 0.453402 \t TrainAcc 88.805060\n","Epoch 19: TestLoss 1.023744 \t TestAcc 81.261770\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.33it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 20: TrainLoss 0.415365 \t TrainAcc 89.441885\n","Epoch 20: TestLoss 1.021756 \t TestAcc 81.600753\n"],"name":"stdout"},{"output_type":"stream","text":["Training: 100%|██████████| 129/129 [04:25<00:00,  2.06s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 21: TrainLoss 0.454672 \t TrainAcc 88.886768\n","Epoch 21: TestLoss 1.020555 \t TestAcc 81.487759\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Wa3a--xuPX_3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607840426304,"user_tz":-480,"elapsed":892,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"ff6116aa-a97e-4ffd-e5c8-76942f98b458"},"source":["checkpoint = torch.load(\"checkpoint.pt\")\r\n","eff_model.load_state_dict(checkpoint['model'])\r\n","acc = checkpoint[\"accuracy\"]\r\n","print(\"Load Ok, accuracy=\",acc)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Load Ok, accuracy= 81.60075329566875\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzYfj29uvMKZ","executionInfo":{"status":"ok","timestamp":1607823579763,"user_tz":-480,"elapsed":4288,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"9cd3ae48-db36-4d0c-f766-eaa3c5664fd3"},"source":["!unzip checkpoint_best.zip"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Archive:  checkpoint_best.zip\n","  inflating: checkpoint_best.pt      \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F7Hsl2o9LIuf"},"source":["data_loader = {\r\n","        \"train\":\r\n","            torch.utils.data.DataLoader(\r\n","                data_sets[\"train_set\"],\r\n","                batch_size=8,\r\n","                shuffle=True,\r\n","                num_workers=4\r\n","            ),\r\n","\r\n","        \"valid\": torch.utils.data.DataLoader(\r\n","                data_sets[\"val_set\"],\r\n","                batch_size=5,\r\n","                shuffle=False,\r\n","                num_workers=4\r\n","            ),\r\n","    }\r\n","# 微调\r\n","for param in eff_model.parameters():\r\n","    param.requires_grad = True\r\n","lr = 0.001\r\n","optimizer = torch.optim.Adam(eff_model.parameters(), lr=lr)\r\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\r\n","trainer = Trainer(eff_model, criterion, optimizer, device)\r\n","run_epochs_for_loop(trainer, 22, data_loader[\"train\"], data_loader[\"valid\"], exp_lr_scheduler)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMxQ8pefQGOd"},"source":["eff_model = EfficientNet.from_pretrained(\"efficientnet-b7\")\n","print(eff_model.__dict__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"si-fSs_U554_","executionInfo":{"status":"ok","timestamp":1607833506591,"user_tz":-480,"elapsed":68559,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["# 修改test_set为test，增加一个test文件夹嵌套\r\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n","trans = transforms.Compose([\r\n","    transforms.Resize(456),\r\n","    transforms.CenterCrop(456),\r\n","    transforms.ToTensor(),\r\n","    normalize,\r\n","])\r\n","predict_sets = torchvision.datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=trans)\r\n","test_loader = torch.utils.data.DataLoader(\r\n","            predict_sets,\r\n","            batch_size=1, # 一次一张一张的预测\r\n","            shuffle=False,\r\n","            num_workers=4\r\n","        )\r\n","tt = Trainer(eff_model, criterion, optimizer, device)\r\n","predictions = tt.predict(test_loader)\r\n","answer = []\r\n","for index, cls in enumerate(predictions):\r\n","      # print(predictions[index])\r\n","      # break\r\n","      path = predict_sets.imgs[index][0]\r\n","      l = path.split(\"/\")\r\n","      img_name = l[-1]\r\n","      answer.append((img_name, int(predictions[index])+1))\r\n","answer = sorted(answer, key=lambda x: int(x[0].split(\".\")[0]))\r\n","import csv\r\n","with open('test.csv','w', newline=\"\")as f:\r\n","    writer = csv.writer(f)\r\n","    for one in answer:\r\n","\r\n","      writer.writerow([one[0], one[1]])"],"execution_count":30,"outputs":[]}]}