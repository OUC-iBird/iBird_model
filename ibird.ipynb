{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ibird.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbys2KjC47V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a089c3-961c-4b08-9d20-e7e803ce66b2"
      },
      "source": [
        "!pip install overrides\n",
        "!pip install tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Building wheels for collected packages: overrides\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10174 sha256=8656315d41e56746793909360928de41fba431aac651c3b0e27fc890fc9ff286\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built overrides\n",
            "Installing collected packages: overrides\n",
            "Successfully installed overrides-3.1.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgUOogeCE9R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3eb12a-4c00-4a8a-d80d-d2d9ba26bf66"
      },
      "source": [
        "! wget https://dwz.cn/ijPVPQhz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-20 07:07:28--  https://dwz.cn/ijPVPQhz\n",
            "Resolving dwz.cn (dwz.cn)... 182.61.200.113\n",
            "Connecting to dwz.cn (dwz.cn)|182.61.200.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://static.leiphone.com/AI%E7%A0%94%E4%B9%A0%E7%A4%BE_%E9%B8%9F%E7%B1%BB%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E6%95%B0%E6%8D%AE%E9%9B%86.rar [following]\n",
            "--2020-11-20 07:07:31--  https://static.leiphone.com/AI%E7%A0%94%E4%B9%A0%E7%A4%BE_%E9%B8%9F%E7%B1%BB%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E6%95%B0%E6%8D%AE%E9%9B%86.rar\n",
            "Resolving static.leiphone.com (static.leiphone.com)... 47.246.22.227, 47.246.22.229, 47.246.22.228, ...\n",
            "Connecting to static.leiphone.com (static.leiphone.com)|47.246.22.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 320892729 (306M) [application/x-rar-compressed]\n",
            "Saving to: ‘ijPVPQhz’\n",
            "\n",
            "ijPVPQhz            100%[===================>] 306.03M  35.6MB/s    in 8.9s    \n",
            "\n",
            "2020-11-20 07:07:42 (34.5 MB/s) - ‘ijPVPQhz’ saved [320892729/320892729]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcLsfrG9Fvrs"
      },
      "source": [
        "!unrar x ijPVPQhz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfM_yaIJEw-H"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets.folder import accimage_loader, pil_loader\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from typing import Tuple\n",
        "\n",
        "from torch.nn import Module\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "from overrides import overrides\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qcib-_lEcGN"
      },
      "source": [
        "from torch.nn import Module\n",
        "import torchvision.models as models\n",
        "class BilinearModel(nn.Module):\n",
        "    \"\"\"Load model with pretrained weights and initialise new layers.\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes: int = 200) -> None:\n",
        "        \"\"\"Load pretrained model, set new layers with specified number of layers.\"\"\"\n",
        "        super(BilinearModel, self).__init__()\n",
        "        model: nn.Module = models.vgg16(pretrained=True)\n",
        "        self.features: nn.Module = nn.Sequential(*list(model.features)[:-1])\n",
        "        self.classifier: nn.Module = nn.Linear(512 ** 2, num_classes)\n",
        "        self.dropout: nn.Module = nn.Dropout(0.5)\n",
        "        self.softmax: nn.Module = nn.LogSoftmax(dim=1)\n",
        "        nn.init.kaiming_normal_(self.classifier.weight.data)\n",
        "        if self.classifier.bias is not None:\n",
        "            nn.init.constant_(self.classifier.bias.data, val=0)\n",
        "\n",
        "    @overrides\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Extract input features, perform bilinear transform, project to # of classes and return.\"\"\"\n",
        "        outputs: torch.Tensor = self.features(inputs)               # extract features from pretrained base\n",
        "        outputs = outputs.view(-1, 512, 28 ** 2)                    # reshape to batchsize * 512 * 28 ** 2\n",
        "        outputs = self.dropout(outputs)\n",
        "        outputs = torch.bmm(outputs, outputs.permute(0, 2, 1))      # bilinear product\n",
        "        outputs = torch.div(outputs, 28 ** 2)                       # divide by 196 to normalize\n",
        "        outputs = outputs.view(-1, 512 ** 2)                        # reshape to batchsize * 512 * 512\n",
        "        outputs = torch.sign(outputs) * torch.sqrt(outputs + 1e-5)  # signed square root normalization\n",
        "        outputs = nn.functional.normalize(outputs, p=2, dim=1)      # l2 normalization\n",
        "        outputs = self.dropout(outputs)\n",
        "        outputs = self.classifier(outputs)\n",
        "        # outputs = self.softmax(outputs)\n",
        "        return outputs\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n19xOsLmEhpb"
      },
      "source": [
        "\"\"\"Trainer class to abstract rudimentary training loop.\"\"\"\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch.nn import Module\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class Trainer(object):\n",
        "    \"\"\"Trainer class to abstract rudimentary training loop.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            model: Module,\n",
        "            criterion: Module,\n",
        "            optimizer: Optimizer,\n",
        "            device: torch.device) -> None:\n",
        "        \"\"\"Set trainer class with model, criterion, optimizer. (Data is passed to train/eval).\"\"\"\n",
        "        super(Trainer, self).__init__()\n",
        "        self.model: Module = model\n",
        "        self.criterion: Module = criterion\n",
        "        self.optimizer: Optimizer = optimizer\n",
        "        self.device: torch.device = device\n",
        "\n",
        "    def train(self, loader: DataLoader) -> Tuple[float, float]:\n",
        "        \"\"\"Train model using batches from loader and return accuracy and loss.\"\"\"\n",
        "        total_loss, total_acc = 0.0, 0.0\n",
        "        self.model.train()\n",
        "        try:\n",
        "            with tqdm(enumerate(loader), total=len(loader), desc='Training') as proc:\n",
        "                for _, (inputs, targets) in proc:\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    targets = targets.to(self.device)\n",
        "                    outputs = self.model(inputs)\n",
        "                    loss = self.criterion(outputs, targets)\n",
        "                    self.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total_loss += loss.item()\n",
        "                    total_acc += (predicted == targets).float().sum().item() / targets.numel()\n",
        "        except KeyboardInterrupt:\n",
        "            # 异常情况关闭\n",
        "            proc.close()\n",
        "        proc.close()\n",
        "        return total_loss / len(loader), 100.0 * total_acc / len(loader)\n",
        "\n",
        "    def test(self, loader: DataLoader) -> Tuple[float, float]:\n",
        "        \"\"\"Evaluate model using batches from loader and return accuracy and loss.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            total_loss, total_acc = 0.0, 0.0\n",
        "            self.model.eval()\n",
        "            for _, (inputs, targets) in tqdm(enumerate(loader), total=len(loader), desc='Testing '):\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "                \n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                \n",
        "                total_loss += loss.item()\n",
        "                total_acc += (predicted == targets).float().sum().item() / targets.numel()\n",
        "        return total_loss / len(loader), 100.0 * total_acc / len(loader)   \n",
        "    def predict(self, loader: DataLoader):\n",
        "        results = []\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(self.device)\n",
        "            outputs = self.model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            results.append(predicted)\n",
        "        return results\n",
        "def run_epochs_for_loop(\n",
        "        trainer: Trainer,\n",
        "        epochs: int,\n",
        "        train_loader: DataLoader,\n",
        "        test_loader: DataLoader,\n",
        "        scheduler: ReduceLROnPlateau = None):\n",
        "    \"\"\"Run train + evaluation loop for specified epochs.\n",
        "\n",
        "    Save checkpoint to specified save folder when better optimum is found.\n",
        "    If LR scheduler is specified, change LR accordingly.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        (train_loss, train_acc) = trainer.train(train_loader)\n",
        "        (test_loss, test_acc) = trainer.test(test_loader)\n",
        "        print()\n",
        "        print(\"Epoch %d: TrainLoss %f \\t TrainAcc %f\" % (epoch, train_loss, train_acc))\n",
        "        print(\"Epoch %d: TestLoss %f \\t TestAcc %f\" % (epoch, test_loss, test_acc))\n",
        "        # 动态更新学习率\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(test_acc)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tROrqDNtE72d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff37a40e-c146-4117-eed7-42413838fdf1"
      },
      "source": [
        "data_dir = \"./AI研习社_鸟类识别比赛数据集\"\n",
        "selection = [\"train_set\", \"val_set\"]\n",
        "# pretrained_data_dir = \"./imagenet_class_index.json\"\n",
        "train_labels = os.path.join(data_dir, \"train_pname_to_index.csv\")\n",
        "valid_labels = os.path.join(data_dir, \"val_pname_to_index.csv\")\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    from torchvision import get_image_backend\n",
        "    if get_image_backend() == 'accimage':\n",
        "        return accimage_loader(path)\n",
        "    else:\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path, data_label_path, data_transform, data_loader=default_loader):\n",
        "        \"\"\"\n",
        "\n",
        "        :param data_path: 要读取的文件的路径\n",
        "        :param data_label_path: 标签数据的路径\n",
        "        :param data_transform: 数据变换模式\n",
        "        :param data_loader: 加载方法\n",
        "        \"\"\"\n",
        "        # 在label文件中注意不要加上标签\n",
        "        df = pd.read_csv(data_label_path, header=None)\n",
        "        self.data_loader = data_loader\n",
        "        self.data_transform = data_transform\n",
        "        self.data_path = data_path\n",
        "        # 获取文件夹下的全部图片名\n",
        "        # self.img_names = os.listdir(os.getcwd())\n",
        "        # self.labels = [\" \".join(img_name.split(\".\")[1].split(\"_\")[:-1]) for img_name in self.img_names]\n",
        "        self.img_names = list(df[0])\n",
        "        self.labels = list(df[1])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        img_name = self.img_names[item]\n",
        "        img_path = os.path.join(self.data_path, img_name)\n",
        "        label = self.labels[item]\n",
        "        img = self.data_loader(img_path)\n",
        "        try:\n",
        "            img = self.data_transform(img)\n",
        "            return img, label-1\n",
        "        except:\n",
        "            raise Exception(\"cannot transform image: {}\".format(img_name))\n",
        "\n",
        "\n",
        "def show_raw_data():\n",
        "    pass\n",
        "\n",
        "\n",
        "def show_dataset():\n",
        "    pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using gpu: %s\" % torch.cuda.is_available())\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "    formats = {\n",
        "        'train_set': [\n",
        "            transforms.Resize(448),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(5),\n",
        "            transforms.RandomCrop(448),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ],\n",
        "        'val_set': [\n",
        "            transforms.Resize(448),\n",
        "            transforms.CenterCrop(448),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ],\n",
        "    }\n",
        "    data_label_paths = {\n",
        "        \"train_set\": train_labels,\n",
        "        \"val_set\": valid_labels,\n",
        "    }\n",
        "    # train_format = formats[\"train\"]\n",
        "    # valid_format = formats[\"valid\"]\n",
        "    data_sets = {}\n",
        "    # for one in selection:\n",
        "    #     data_sets[one] = datasets.ImageFolder(\n",
        "    #         os.path.join(data_dir, one),\n",
        "    #         transforms.Compose(formats[one]),\n",
        "    #     )\n",
        "    for one in selection:\n",
        "        data_sets[one] = CustomDataset(os.path.join(data_dir, one),\n",
        "                                       data_label_paths[one],\n",
        "                                       transforms.Compose(formats[one]))\n",
        "    data_loader = {\n",
        "        \"train\":\n",
        "            torch.utils.data.DataLoader(\n",
        "                data_sets[\"train_set\"],\n",
        "                batch_size=32,\n",
        "                shuffle=True,\n",
        "                num_workers=4\n",
        "            ),\n",
        "\n",
        "        \"valid\": torch.utils.data.DataLoader(\n",
        "                data_sets[\"val_set\"],\n",
        "                batch_size=5,\n",
        "                shuffle=False,\n",
        "                num_workers=4\n",
        "            ),\n",
        "    }\n",
        "    model = BilinearModel(num_classes=200)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # criterion = nn.NLLLoss()\n",
        "    model.to(device)\n",
        "    criterion.to(device)\n",
        "    lr = 0.001\n",
        "    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=lr)\n",
        "\n",
        "    trainer = Trainer(model, criterion, optimizer, device)\n",
        "    reduceLROnPlateau = ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='max',\n",
        "        factor=0.1,\n",
        "        patience=10,\n",
        "        verbose=True,\n",
        "        threshold=1e-4,\n",
        "    )\n",
        "    # 预训练全连接层\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "    run_epochs_for_loop(trainer, 20, data_loader[\"train\"], data_loader[\"valid\"], reduceLROnPlateau)\n",
        "    \n",
        "    # 整体训练\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = True\n",
        "    reduceLROnPlateau = ReduceLROnPlateau(optimizer, mode='max')\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    run_epochs_for_loop(trainer, 5, data_loader[\"train\"], data_loader[\"valid\"], reduceLROnPlateau)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 6/258 [00:05<04:07,  1.02it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ1KcdYLiCoy"
      },
      "source": [
        "# 修改test_set为test，增加一个test文件夹嵌套\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "trans = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    # transforms.CenterCrop(448),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "predict_sets = torchvision.datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=trans)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "            predict_sets,\n",
        "            batch_size=1, # 一次一张一张的预测\n",
        "            shuffle=False,\n",
        "            num_workers=4\n",
        "        )\n",
        "tt = Trainer(model, criterion, optimizer, device)\n",
        "predictions = tt.predict(test_loader)\n",
        "answer = []\n",
        "for index, cls in enumerate(predictions):\n",
        "      # print(predictions[index])\n",
        "      # break\n",
        "      path = predict_sets.imgs[index][0]\n",
        "      l = path.split(\"/\")\n",
        "      img_name = l[-1]\n",
        "      answer.append((img_name, int(predictions[index])+1))\n",
        "answer = sorted(answer, key=lambda x: int(x[0].split(\".\")[0]))\n",
        "import csv\n",
        "with open('test.csv','w', newline=\"\")as f:\n",
        "    writer = csv.writer(f)\n",
        "    for one in answer:\n",
        "\n",
        "      writer.writerow([one[0], one[1]])"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}