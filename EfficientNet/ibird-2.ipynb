{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ibird-2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2pjkw7L3eRtJaDQjEPNki"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6susXe-Y7o0A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607684247091,"user_tz":-480,"elapsed":16109,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"28eed78f-eed3-45c4-9dda-0bac262fadf3"},"source":["!pip install overrides\n","!pip install tqdm\n","!pip install efficientnet_pytorch\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting overrides\n","  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n","Building wheels for collected packages: overrides\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10175 sha256=e7510755d198bf3295d2bd2eb1ff0facdce5f325ac05ee416d1ec6d6abf76b7d\n","  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n","Successfully built overrides\n","Installing collected packages: overrides\n","Successfully installed overrides-3.1.0\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n","Collecting efficientnet_pytorch\n","  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.7.0+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16030 sha256=75b516e9f43b72ba08cc26745770712186b85b5ae7dbfb7cd3a8685882ec8487\n","  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P5QHRyF979UG"},"source":["!wget https://dwz.cn/ijPVPQhz\n","!unrar x ijPVPQhz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CY8DBzjHACU4","executionInfo":{"status":"ok","timestamp":1607707870383,"user_tz":-480,"elapsed":933,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["# 头文件\n","from overrides import overrides\n","import torch.nn as nn\n","import torch\n","import pandas as pd\n","from torchvision.datasets.folder import accimage_loader, pil_loader\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import os\n","import torchvision\n","from torchvision import transforms\n","from typing import Tuple\n","from torch.nn import Module\n","from torch.optim.optimizer import Optimizer\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from efficientnet_pytorch import EfficientNet"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"JmliupqIARrg","executionInfo":{"status":"ok","timestamp":1607702571678,"user_tz":-480,"elapsed":3524,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["class Trainer:\n","    \"\"\"Trainer class to abstract rudimentary training loop.\"\"\"\n","\n","    def __init__(\n","            self,\n","            model: Module,\n","            criterion: Module,\n","            optimizer: Optimizer,\n","            device: torch.device) -> None:\n","        \"\"\"Set trainer class with model, criterion, optimizer. (Data is passed to train/eval).\"\"\"\n","        super(Trainer, self).__init__()\n","        self.model: Module = model\n","        self.criterion: Module = criterion\n","        self.optimizer: Optimizer = optimizer\n","        self.device: torch.device = device\n","\n","    def train(self, loader: DataLoader) -> Tuple[float, float]:\n","        \"\"\"Train model using batches from loader and return accuracy and loss.\"\"\"\n","        total_loss, total_acc = 0.0, 0.0\n","        self.model.train()\n","        try:\n","            with tqdm(enumerate(loader), total=len(loader), desc='Training') as proc:\n","                for _, (inputs, targets) in proc:\n","                    inputs = inputs.to(self.device)\n","                    targets = targets.to(self.device)\n","                    outputs = self.model(inputs)\n","                    loss = self.criterion(outputs, targets)\n","                    self.optimizer.zero_grad()\n","                    loss.backward()\n","                    self.optimizer.step()\n","                    _, predicted = torch.max(outputs, 1)\n","                    total_loss += loss.item()\n","                    total_acc += (predicted == targets).float().sum().item() / targets.numel()\n","        except Exception as e:\n","            # 异常情况关闭\n","            print(\"Running Error in training, \", e)\n","            proc.close()\n","            return -1, -1\n","        proc.close()\n","        return total_loss / len(loader), 100.0 * total_acc / len(loader)\n","\n","    def test(self, loader: DataLoader) -> Tuple[float, float]:\n","        \"\"\"Evaluate model using batches from loader and return accuracy and loss.\"\"\"\n","        with torch.no_grad():\n","            total_loss, total_acc = 0.0, 0.0\n","            self.model.eval()\n","            try:\n","                with tqdm(enumerate(loader), total=len(loader), desc='Testing ') as proc:\n","                    for _, (inputs, targets) in proc:\n","                        inputs = inputs.to(self.device)\n","                        targets = targets.to(self.device)\n","                        outputs = self.model(inputs)\n","                        loss = self.criterion(outputs, targets)\n","                        _, predicted = torch.max(outputs, 1)\n","                        total_loss += loss.item()\n","                        total_acc += (predicted == targets).float().sum().item() / targets.numel()\n","            except Exception as e:\n","                proc.close()\n","                print(\"Running Error in validating,\", e)\n","                return -1, -1\n","            proc.close()\n","        return total_loss / len(loader), 100.0 * total_acc / len(loader)\n","\n","    def predict(self, loader: DataLoader):\n","        results = []\n","        for inputs, targets in loader:\n","            inputs = inputs.to(self.device)\n","            outputs = self.model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            results.append(predicted)\n","        return results\n","\n","\n","def run_epochs_for_loop(\n","        trainer: Trainer,\n","        epochs: int,\n","        train_loader: DataLoader,\n","        test_loader: DataLoader,\n","        scheduler: ReduceLROnPlateau = None):\n","    # Run train + evaluation loop for specified epochs.\n","    global best \n","    for epoch in range(epochs):\n","        (train_loss, train_acc) = trainer.train(train_loader)\n","        (test_loss, test_acc) = trainer.test(test_loader)\n","        print()\n","        print(\"Epoch %d: TrainLoss %f \\t TrainAcc %f\" % (epoch+1, train_loss, train_acc))\n","        print(\"Epoch %d: TestLoss %f \\t TestAcc %f\" % (epoch+1, test_loss, test_acc))\n","        # 动态更新学习率\n","        if scheduler is not None:\n","            scheduler.step(test_acc)\n","        # 保存训练的结果\n","        if test_acc > best:\n","            best = test_acc\n","            save_checkpoint(trainer, epoch, test_acc, \"./\")\n","\n","\n","def save_checkpoint(trainer: Trainer, epoch: int, accuracy: float, path: str):\n","    # 保存训练结果\n","    path = os.path.join(path, \"checkpoint.pt\")\n","    checkpoint = {\n","        \"model\": trainer.model.state_dict(),\n","        \"optimizer\": trainer.optimizer.state_dict(),\n","        \"epoch\": epoch,\n","        \"accuracy\": accuracy,\n","    }\n","    torch.save(checkpoint, path)\n","\n","\n","def save_model(model, path):\n","    # 只保存模型的实例变量\n","    if torch.__version__ >= \"1.6.0\":\n","        torch.save(model.state_dict(), path, _use_new_zipfile_serialization=False)\n","    else:\n","        torch.save(model.state_dict(), path)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"AiHLGa3IsuSn","executionInfo":{"status":"ok","timestamp":1607688873074,"user_tz":-480,"elapsed":911,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["\r\n","\r\n","def conv3x3(in_planes, out_planes, stride=1):\r\n","    # \"3x3 convolution with padding\"\r\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n","                     padding=1, bias=False)\r\n","\r\n","\r\n","class ChannelAttention(nn.Module):\r\n","    def __init__(self, in_planes, ratio=16):\r\n","        super(ChannelAttention, self).__init__()\r\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # 压缩空间\r\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\r\n","\r\n","        self.fc1 = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\r\n","        self.relu1 = nn.ReLU()\r\n","        self.fc2 = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\r\n","\r\n","        self.sigmoid = nn.Sigmoid()\r\n","\r\n","    def forward(self, x):\r\n","        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\r\n","        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\r\n","        out = avg_out + max_out  # [b, C, 1, 1]\r\n","        return self.sigmoid(out)\r\n","\r\n","\r\n","class SpatialAttention(nn.Module):\r\n","    def __init__(self, kernel_size=7):\r\n","        super(SpatialAttention, self).__init__()\r\n","\r\n","        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\r\n","        padding = 3 if kernel_size == 7 else 1\r\n","\r\n","        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\r\n","        self.sigmoid = nn.Sigmoid()\r\n","\r\n","    def forward(self, x):\r\n","        avg_out = torch.mean(x, dim=1, keepdim=True)  # 压缩通道\r\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)   # 压缩通道\r\n","        x = torch.cat([avg_out, max_out], dim=1)  # [b, 1, h, w]\r\n","        x = self.conv1(x)\r\n","        return self.sigmoid(x)\r\n","\r\n","\r\n","class BasicBlock(nn.Module):\r\n","    expansion = 1\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n","        super(BasicBlock, self).__init__()\r\n","        self.conv1 = conv3x3(inplanes, planes, stride)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.conv2 = conv3x3(planes, planes)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","\r\n","        self.ca = ChannelAttention(planes)\r\n","        self.sa = SpatialAttention()\r\n","\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = x\r\n","\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","\r\n","        out = self.ca(out) * out\r\n","        out = self.sa(out) * out\r\n","\r\n","        if self.downsample is not None:\r\n","            residual = self.downsample(x)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","\r\n","        return out\r\n","\r\n","\r\n","class Bottleneck(nn.Module):\r\n","    expansion = 4\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n","        super(Bottleneck, self).__init__()\r\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\r\n","                               padding=1, bias=False)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\r\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","\r\n","        self.ca = ChannelAttention(planes * 4)\r\n","        self.sa = SpatialAttention()\r\n","\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = x\r\n","\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv3(out)\r\n","        out = self.bn3(out)\r\n","\r\n","        out = self.ca(out) * out\r\n","        out = self.sa(out) * out\r\n","\r\n","        if self.downsample is not None:\r\n","            residual = self.downsample(x)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","\r\n","        return out"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"rymNvtvxs7G1","executionInfo":{"status":"ok","timestamp":1607688941237,"user_tz":-480,"elapsed":919,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["class EfficientNetWithAttention(nn.Module):\r\n","\r\n","    def __init__(self, num_classes: int = 200):\r\n","        super(EfficientNetWithAttention, self).__init__()\r\n","        self.eff_model = EfficientNet.from_pretrained(\"efficientnet-b5\")\r\n","        self._avg_pooling = nn.AdaptiveAvgPool2d(output_size=1)\r\n","        self._dropout = nn.Dropout(p=0.5, inplace=False)\r\n","\r\n","        self._fc = nn.Linear(in_features=self.eff_model._fc.in_features, out_features=num_classes, bias=True)\r\n","        self.ca_head = ChannelAttention(64)\r\n","        self.sa = SpatialAttention()\r\n","        self.ca_tail = ChannelAttention(self.eff_model._fc.in_features)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.eff_model.extract_features(x)\r\n","        x = self.ca_tail(x) * x\r\n","        x = self.sa(x) * x\r\n","\r\n","        x = self._avg_pooling(x)\r\n","        if self.eff_model._global_params.include_top:\r\n","            x = x.flatten(start_dim=1)\r\n","            x = self._dropout(x)\r\n","            x = self._fc(x)\r\n","        return x"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wizkwi7MANbJ","executionInfo":{"status":"ok","timestamp":1607689299098,"user_tz":-480,"elapsed":1459,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"6300a322-5856-4b8e-c1bb-993809d282a1"},"source":["\n","data_dir = \"./AI研习社_鸟类识别比赛数据集\"\n","selection = [\"train_set\", \"val_set\"]\n","train_labels = os.path.join(data_dir, \"train_pname_to_index.csv\")\n","valid_labels = os.path.join(data_dir, \"val_pname_to_index.csv\")\n","\n","\n","def default_loader(path):\n","    from torchvision import get_image_backend\n","    if get_image_backend() == 'accimage':\n","        return accimage_loader(path)\n","    else:\n","        return pil_loader(path)\n","\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, data_path, data_label_path, data_transform, data_loader=default_loader):\n","        \"\"\"\n","\n","        :param data_path: 要读取的文件的路径\n","        :param data_label_path: 标签数据的路径\n","        :param data_transform: 数据变换模式\n","        :param data_loader: 加载方法\n","        \"\"\"\n","        # 在label文件中注意不要加上标签\n","        df = pd.read_csv(data_label_path, header=None)\n","        self.data_loader = data_loader\n","        self.data_transform = data_transform\n","        self.data_path = data_path\n","        # 获取文件夹下的全部图片名\n","        self.img_names = list(df[0])\n","        self.labels = list(df[1])\n","\n","    def __len__(self):\n","        return len(self.img_names)\n","\n","    def __getitem__(self, item):\n","        img_name = self.img_names[item]\n","        img_path = os.path.join(self.data_path, img_name)\n","        label = self.labels[item]\n","        img = self.data_loader(img_path)\n","        try:\n","            img = self.data_transform(img)\n","            return img, label-1\n","        except:\n","            raise Exception(\"cannot transform image: {}\".format(img_name))\n","\n","\n","if __name__ == '__main__':\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    formats = {\n","        'train_set': [\n","            transforms.Resize(456),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomRotation(5),\n","            transforms.RandomCrop(456),\n","            transforms.ToTensor(),\n","            normalize,\n","        ],\n","        'val_set': [\n","            transforms.Resize(456),\n","            transforms.CenterCrop(456),\n","            transforms.ToTensor(),\n","            normalize,\n","        ],\n","    }\n","    data_label_paths = {\n","        \"train_set\": train_labels,\n","        \"val_set\": valid_labels,\n","    }\n","    data_sets = {}\n","    for one in selection:\n","        data_sets[one] = CustomDataset(os.path.join(data_dir, one),\n","                                       data_label_paths[one],\n","                                       transforms.Compose(formats[one]))\n","    data_loader = {\n","        \"train\":\n","            torch.utils.data.DataLoader(\n","                data_sets[\"train_set\"],\n","                batch_size=64,\n","                shuffle=True,\n","                num_workers=4\n","            ),\n","\n","        \"valid\": torch.utils.data.DataLoader(\n","                data_sets[\"val_set\"],\n","                batch_size=5,\n","                shuffle=False,\n","                num_workers=4\n","            ),\n","    }\n","    # eff_model = EfficientNet.from_pretrained(\"efficientnet-b5\")\n","    # in_features = eff_model._fc.in_features\n","    # eff_model._fc = nn.Linear(in_features, 200)\n","    eff_model = EfficientNetWithAttention()\n","    criterion = nn.CrossEntropyLoss()\n","    lr = 0.001\n","    optimizer = torch.optim.Adam(eff_model._fc.parameters(), lr=lr)\n","    trainer = Trainer(eff_model, criterion, optimizer, device)\n","    \n","    \n","    # checkpoint = torch.load(\"./checkpoint.pt\")\n","    # eff_model.load_state_dict(checkpoint['model'])\n","    # acc = checkpoint[\"accuracy\"]\n","    # print(\"Load Ok, accuracy=\",acc)\n","    eff_model.to(device)\n","    criterion.to(device)\n","    best = 0\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":724},"id":"6O9kNQpDILnO","executionInfo":{"status":"error","timestamp":1607707595755,"user_tz":-480,"elapsed":1492291,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"00c98cdf-f8b8-4c69-daa7-f9b8b5f38f02"},"source":["trainer = Trainer(eff_model, criterion, optimizer, device)\r\n","data_loader = {\r\n","        \"train\":\r\n","            torch.utils.data.DataLoader(\r\n","                data_sets[\"train_set\"],\r\n","                batch_size=32,\r\n","                shuffle=True,\r\n","                num_workers=4\r\n","            ),\r\n","\r\n","        \"valid\": torch.utils.data.DataLoader(\r\n","                data_sets[\"val_set\"],\r\n","                batch_size=5,\r\n","                shuffle=False,\r\n","                num_workers=4\r\n","            ),\r\n","    }\r\n","for param in eff_model.parameters():\r\n","    param.requires_grad = False\r\n","for param in eff_model._fc.parameters():\r\n","    param.requires_grad = True\r\n","reduceLROnPlateau = ReduceLROnPlateau(\r\n","        optimizer,\r\n","        mode='max',\r\n","        factor=0.1,\r\n","        patience=10,\r\n","        verbose=True,\r\n","        threshold=1e-4,\r\n","    )\r\n","run_epochs_for_loop(trainer, 5, data_loader[\"train\"], data_loader[\"valid\"], reduceLROnPlateau)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Training: 100%|██████████| 258/258 [04:34<00:00,  1.06s/it]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.31it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 1: TrainLoss 0.893068 \t TrainAcc 75.063702\n","Epoch 1: TestLoss 0.998046 \t TestAcc 72.787194\n"],"name":"stdout"},{"output_type":"stream","text":["Training: 100%|██████████| 258/258 [04:40<00:00,  1.09s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.34it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 2: TrainLoss 0.790477 \t TrainAcc 78.317453\n","Epoch 2: TestLoss 0.930862 \t TestAcc 74.858757\n"],"name":"stdout"},{"output_type":"stream","text":["Training: 100%|██████████| 258/258 [04:39<00:00,  1.08s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 3: TrainLoss 0.757954 \t TrainAcc 78.981392\n","Epoch 3: TestLoss 0.901910 \t TestAcc 75.762712\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 258/258 [04:38<00:00,  1.08s/it]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 4: TrainLoss 0.715905 \t TrainAcc 80.661876\n","Epoch 4: TestLoss 0.882239 \t TestAcc 76.384181\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training:  55%|█████▍    | 141/258 [02:33<02:07,  1.09s/it]\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-eeda0dc36aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mrun_epochs_for_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduceLROnPlateau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-bfea6f4188b2>\u001b[0m in \u001b[0;36mrun_epochs_for_loop\u001b[0;34m(trainer, epochs, train_loader, test_loader, scheduler)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-bfea6f4188b2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-7327e7948351>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meff_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_tail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# scale drop connect_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# Head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# skip connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Wa3a--xuPX_3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607707602793,"user_tz":-480,"elapsed":1268,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}},"outputId":"629187b5-12b4-40c1-d9a2-a4e38e15e1da"},"source":["checkpoint = torch.load(\"checkpoint.pt\")\r\n","eff_model.load_state_dict(checkpoint['model'])\r\n","acc = checkpoint[\"accuracy\"]\r\n","print(\"Load Ok, accuracy=\",acc)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Load Ok, accuracy= 81.65725047080996\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7Hsl2o9LIuf","outputId":"a0decfdd-486d-4c0f-8aba-095e44be9cff"},"source":["data_loader = {\r\n","        \"train\":\r\n","            torch.utils.data.DataLoader(\r\n","                data_sets[\"train_set\"],\r\n","                batch_size=8,\r\n","                shuffle=True,\r\n","                num_workers=4\r\n","            ),\r\n","\r\n","        \"valid\": torch.utils.data.DataLoader(\r\n","                data_sets[\"val_set\"],\r\n","                batch_size=5,\r\n","                shuffle=False,\r\n","                num_workers=4\r\n","            ),\r\n","    }\r\n","# 微调\r\n","for param in eff_model.parameters():\r\n","    param.requires_grad = True\r\n","lr = 0.001\r\n","optimizer = torch.optim.Adam(eff_model.parameters(), lr=lr)\r\n","\r\n","trainer = Trainer(eff_model, criterion, optimizer, device)\r\n","reduceLROnPlateau = ReduceLROnPlateau(\r\n","    optimizer,\r\n","    mode='max',\r\n",")\r\n","run_epochs_for_loop(trainer, 22, data_loader[\"train\"], data_loader[\"valid\"], reduceLROnPlateau)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training: 100%|██████████| 1032/1032 [15:33<00:00,  1.11it/s]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.34it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 1: TrainLoss 1.250624 \t TrainAcc 65.039567\n","Epoch 1: TestLoss 1.173324 \t TestAcc 68.926554\n"],"name":"stdout"},{"output_type":"stream","text":["Training: 100%|██████████| 1032/1032 [15:32<00:00,  1.11it/s]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.31it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 2: TrainLoss 0.968522 \t TrainAcc 72.549257\n","Epoch 2: TestLoss 1.087554 \t TestAcc 71.355932\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:33<00:00,  1.11it/s]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.31it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 3: TrainLoss 0.814626 \t TrainAcc 76.481751\n","Epoch 3: TestLoss 1.083911 \t TestAcc 72.937853\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:35<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.30it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 4: TrainLoss 0.709442 \t TrainAcc 78.896156\n","Epoch 4: TestLoss 1.054137 \t TestAcc 73.917137\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:34<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 5: TrainLoss 0.639518 \t TrainAcc 80.862403\n","Epoch 5: TestLoss 0.989772 \t TestAcc 75.216573\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:34<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 6: TrainLoss 0.597760 \t TrainAcc 82.186693\n","Epoch 6: TestLoss 1.126406 \t TestAcc 72.787194\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:34<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 7: TrainLoss 0.532099 \t TrainAcc 83.729005\n","Epoch 7: TestLoss 1.092530 \t TestAcc 74.293785\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:34<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:55<00:00,  6.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 8: TrainLoss 0.494044 \t TrainAcc 84.964470\n","Epoch 8: TestLoss 0.952912 \t TestAcc 77.344633\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:35<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.26it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 9: TrainLoss 0.436656 \t TrainAcc 86.712694\n","Epoch 9: TestLoss 1.208841 \t TestAcc 72.674200\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:34<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 10: TrainLoss 0.392479 \t TrainAcc 87.891634\n","Epoch 10: TestLoss 1.131738 \t TestAcc 73.898305\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:34<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 11: TrainLoss 0.391587 \t TrainAcc 88.073320\n","Epoch 11: TestLoss 1.108797 \t TestAcc 74.463277\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training: 100%|██████████| 1032/1032 [15:34<00:00,  1.10it/s]\n","Testing : 100%|██████████| 354/354 [00:56<00:00,  6.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 12: TrainLoss 0.355265 \t TrainAcc 89.219961\n","Epoch 12: TestLoss 1.194660 \t TestAcc 73.540490\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Training:  42%|████▏     | 438/1032 [06:36<08:57,  1.11it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"XMxQ8pefQGOd"},"source":["eff_model = EfficientNet.from_pretrained(\"efficientnet-b7\")\n","print(eff_model.__dict__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"si-fSs_U554_","executionInfo":{"status":"ok","timestamp":1607708080546,"user_tz":-480,"elapsed":82044,"user":{"displayName":"two C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmCYT2i1XXWN3y8CZYOelNmg7KB0vzU88wNm5e=s64","userId":"06853321191590263386"}}},"source":["# 修改test_set为test，增加一个test文件夹嵌套\r\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n","trans = transforms.Compose([\r\n","    transforms.Resize((456, 456)),\r\n","    transforms.ToTensor(),\r\n","    normalize,\r\n","])\r\n","predict_sets = torchvision.datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=trans)\r\n","test_loader = torch.utils.data.DataLoader(\r\n","            predict_sets,\r\n","            batch_size=1, # 一次一张一张的预测\r\n","            shuffle=False,\r\n","            num_workers=4\r\n","        )\r\n","tt = Trainer(eff_model, criterion, optimizer, device)\r\n","predictions = tt.predict(test_loader)\r\n","answer = []\r\n","for index, cls in enumerate(predictions):\r\n","      # print(predictions[index])\r\n","      # break\r\n","      path = predict_sets.imgs[index][0]\r\n","      l = path.split(\"/\")\r\n","      img_name = l[-1]\r\n","      answer.append((img_name, int(predictions[index])+1))\r\n","answer = sorted(answer, key=lambda x: int(x[0].split(\".\")[0]))\r\n","import csv\r\n","with open('test.csv','w', newline=\"\")as f:\r\n","    writer = csv.writer(f)\r\n","    for one in answer:\r\n","\r\n","      writer.writerow([one[0], one[1]])"],"execution_count":26,"outputs":[]}]}